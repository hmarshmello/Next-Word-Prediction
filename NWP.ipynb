{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 594198 characters\n"
     ]
    }
   ],
   "source": [
    "#Read the Data\n",
    "text = open('1661-0.txt', 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of th\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process the text\n",
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[61, 62, 63, 64, 65, 66, 67], [84, 85, 86]]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(594198,), dtype=int64, numpy=array([100,   2,   1, ...,   1,   2,   1], dtype=int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction Task\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "P\n",
      "r\n",
      "o\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\\xef\\xbb\\xbf' b'\\r' b'\\n' b'P' b'r' b'o' b'j' b'e' b'c' b't' b' ' b'G'\n",
      " b'u' b't' b'e' b'n' b'b' b'e' b'r' b'g' b\"'\" b's' b' ' b'T' b'h' b'e'\n",
      " b' ' b'A' b'd' b'v' b'e' b'n' b't' b'u' b'r' b'e' b's' b' ' b'o' b'f'\n",
      " b' ' b'S' b'h' b'e' b'r' b'l' b'o' b'c' b'k' b' ' b'H' b'o' b'l' b'm'\n",
      " b'e' b's' b',' b' ' b'b' b'y' b' ' b'A' b'r' b't' b'h' b'u' b'r' b' '\n",
      " b'C' b'o' b'n' b'a' b'n' b' ' b'D' b'o' b'y' b'l' b'e' b'\\r' b'\\n' b'\\r'\n",
      " b'\\n' b'T' b'h' b'i' b's' b' ' b'e' b'B' b'o' b'o' b'k' b' ' b'i' b's'\n",
      " b' ' b'f' b'o' b'r' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\xef\\xbb\\xbf\\r\\nProject Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\\r\\n\\r\\nThis eBook is for \"\n",
      "b'the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, '\n",
      "b'give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook'\n",
      "b' or online at www.gutenberg.net\\r\\n\\r\\n\\r\\nTitle: The Adventures of Sherlock Holmes\\r\\n\\r\\nAuthor: Arthur Conan'\n",
      "b' Doyle\\r\\n\\r\\nRelease Date: November 29, 2002 [EBook #1661]\\r\\nLast Updated: May 20, 2019\\r\\n\\r\\nLanguage: Engl'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"\\xef\\xbb\\xbf\\r\\nProject Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\\r\\n\\r\\nThis eBook is for\"\n",
      "Target: b\"\\r\\nProject Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\\r\\n\\r\\nThis eBook is for \"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create training Batches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Model\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_units = 1024\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 101) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "#Trying the Model\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  25856     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  103525    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,067,685\n",
      "Trainable params: 4,067,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying for the first example in the batch\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 93, 18, 27, 92, 40, 47, 41,  4, 87, 15, 27, 53, 50, 96, 23, 33,\n",
       "       64, 25, 39, 97,  4, 47, 13, 18, 23, 10, 16, 53, 17, 15, 96,  9, 14,\n",
       "        4,  7, 99, 58, 25, 37, 38, 38, 35, 26, 60, 88, 39, 97, 35, 15, 12,\n",
       "       30, 73, 62, 34, 78, 67, 45, 37, 14, 31, 37, 20, 17, 81, 29, 99, 69,\n",
       "       34, 55, 35, 86, 11, 17,  0, 80, 83, 31,  5,  4, 82, 83, 42, 95, 17,\n",
       "       68, 92,  4, 74, 49, 55, 42, 72, 31, 78, 26,  3, 41, 50, 53],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'furnished little chamber, with\\r\\na grey carpet, a large bureau, and a long mirror. Holmes went to the'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'd\\xc3\\xa909\\xc3\\xa8IPJ!\\xc2\\xa3-9VS\\xe2\\x80\\x985Bd7H\\xe2\\x80\\x99!P*05\\'.V/-\\xe2\\x80\\x98&,!$\\xe2\\x80\\x9d[7FGGD8_\\xc2\\xbdH\\xe2\\x80\\x99D-)?mbCrgNF,@F2/u;\\xe2\\x80\\x9diCXDz(/[UNK]tw@\"!vwK\\xe2\\x80\\x94/h\\xc3\\xa8!nRXKl@r8 JSV'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Model\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 101)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.6146817, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.95569"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring Checkpoints\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executing the TRAINING\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "91/91 [==============================] - 284s 3s/step - loss: 3.0293\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 250s 3s/step - loss: 2.2351\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 199s 2s/step - loss: 2.0132\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 198s 2s/step - loss: 1.8267\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 197s 2s/step - loss: 1.6771\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 197s 2s/step - loss: 1.5469\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 197s 2s/step - loss: 1.4420\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 198s 2s/step - loss: 1.3600\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 199s 2s/step - loss: 1.2926\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 198s 2s/step - loss: 1.2352\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 199s 2s/step - loss: 1.1845\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 191s 2s/step - loss: 1.1350\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 176s 2s/step - loss: 1.0864\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 176s 2s/step - loss: 1.0374\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 175s 2s/step - loss: 0.9900\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 175s 2s/step - loss: 0.9370\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 175s 2s/step - loss: 0.8837\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 175s 2s/step - loss: 0.8286\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - 178s 2s/step - loss: 0.7695\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 175s 2s/step - loss: 0.7093\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the TEXT\n",
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "\n",
      "“Boscombe Pool, then?”\n",
      "\n",
      "“Tell me that I had shown you but at a usually interested in A have\n",
      "better for you. You have fastened sungly cold towards a girl,\n",
      "for he looked outside cold well with the tasket-chain, as he came\n",
      "in a disqualing of his share wife as every friends, they are, as her commissions we had\n",
      "advertured with my face topoded a while we had then.\n",
      "\n",
      "“‘Well?’ he consedient to close circle turned to the\n",
      "records of his congrattle ting of the strange and struck as if a hopely shutters up to\n",
      "ten minday, each Maustered away by easy other late and stronger rambalsquair, the\n",
      "flowing was of ‘Fore allow, I am sorry tell,” said he. “But away we\n",
      "have come with—you in the Pasistance of the house?”\n",
      "\n",
      "“I told you all about it you would not talk all Gord. Two years ago, his wife’s\n",
      "cried swiftly, and, faintly he turned out of the window rose up\n",
      "his evid head, shall observed Holmes, spring in his chair and eyes to the\n",
      "slip of the fity and little from the woods of Bohemia in \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.441141128540039\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'ROMEO: I must put the facts at the\\r\\ncase, do?\\xe2\\x80\\x99 I\\r\\nwould have done now to put his land, though we heard\\r\\nfrom the first at the old day fellow there may be mneeting in for the\\r\\ndeserts. This thought we heard some glimpses bying a look at\\r\\nwon\\xe2\\x80\\x99t in the Gerlyma, not only one, which sat standing in the\\r\\nmarriage had last, have given me on my upprovinged, and they were\\r\\nto its returned and extraordinary cloids. Of these had find a\\r\\nlittle newspaper shoel away the date of the prace which I have a slush of bantar with my boy and\\r\\nsitting-statement which in many lay happened, but I always believed his\\r\\neyes. But the goose was all drawn turner. As so open his face, which seemed to give us\\r\\nall over into my eightfully. \\xe2\\x80\\x9cI am sure!\\xe2\\x80\\x99\\r\\n\\r\\n\\xe2\\x80\\x9c\\xe2\\x80\\x98Oh,\\xe2\\x80\\x99 says she, was in Jalanate\\xe2\\x80\\x94\\xe2\\x80\\x99s pledgear. \\xe2\\x80\\x9cThey appeared to be kind to\\r\\nyet in its guzzen hat authorita_ly\\r\\nin convenience which it she meathbers, in look at it.\\xe2\\x80\\x9d He opened it every\\r\\nstanding at the locket. \\xe2\\x80\\x9cI will set forth in personall survivor, of sometion\\r\\noutnise'\n",
      " b'ROMEO: now there is a question of The\\r\\nAdventures of Sherlock Holmes. Hed coat stall else in the provision\\r\\nwhich had brought. We have thought a little too good authoritial,\\xe2\\x80\\x9d said Holmes. \\xe2\\x80\\x9cI am confided it all\\r\\nmight give you by butyoned if you saved, \\xe2\\x80\\x98at the\\r\\n  legglopy and disappointment that a cousidor had been left into the\\r\\nbusiness of the footpaths,\\r\\nhe is now destributions, as  we\\xe2\\x80\\x99se, but we were goes out away to the\\r\\ntwinkled glass of Hollest and employers in the United\\r\\nStates. Come at once, curious to Mugus\\r\\nPacked English spread was doing wax. It\\r\\nwas no wonder that no know which you have founds lest there, about\\r\\nfind showing before very little trade.\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cWho can be of considerable step most curious indeed.\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cAnd you are signature with me as to Holmes\\xe2\\x80\\x99 thin; been are about your assistance?\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cYou have been madedy?\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cNone of him yet?\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cExcellent! You have earning this someone was no more to\\r\\nbreak it. An electronic work, though I then right, \\xe2\\x80\\x98you have \\xc2\\xa3\\r\\n505z_.\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cTh'\n",
      " b'ROMEO:\\r\\n\\r\\n\\xe2\\x80\\x9cPrecisely so. Your confive matter!\\xe2\\x80\\x9d He unkedded quietly.\\r\\n\\r\\n\\xe2\\x80\\x9c\\xe2\\x80\\x98Do you know his father? I know horrible!\\xe2\\x80\\x9d I ejaculated.\\r\\n\\r\\n\\xe2\\x80\\x9cThe King is Zate here?\\xe2\\x80\\x9d asked Holmes. \\xe2\\x80\\x9cHow could he\\xe2\\x80\\x99s your reasons who had\\r\\nalready black my private a few minutes on the needested himself.\\r\\n\\r\\n\\xe2\\x80\\x9c\\xe2\\x80\\x98Mr. Hosmer, McCaully I have seen these downstairs, but it\\r\\nis the dury when we were, too!\\xe2\\x80\\x99 said I, \\xe2\\x80\\x98a felt my\\r\\nwife\\xe2\\x80\\x99s enecly beying for times letters,\\xe2\\x80\\x9d said Holmes. \\xe2\\x80\\x9cIt is\\r\\nall day, and simplicy North, John Horner, who is I knew by\\r\\nbegood for craving compuritia. At he loves at least a just hablen\\r\\nshabld by since Wilver? When an actor examined the sent colours, since I begin\\r\\nat the coronet in front of the corner devores of his coat, was opened,\\r\\nright now and a cubbil this emooked open his self-bried a brave long.\\r\\nIt 2ptat and stalled lock and saw that he lived at a hugray-bedifal and uncertaining of it.\\r\\n\\r\\n\\xe2\\x80\\x9cStolen!\\xe2\\x80\\x99 he exclament of Holmes in her way downstairs, but the case\\r\\nof appractic slightly had been a scent.'\n",
      " b'ROMEO:\\r\\n\\r\\n\\xe2\\x80\\x9cNothing.\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cYou have onlens it is not their exp?\\xe2\\x80\\x99s now on that window\\r\\nhealth! Save you as I knew that he is right. Precisely he is dingness the appectary\\r\\nman colourly and retost through the highest with me and baking\\r\\nmoney with his own fargh banks of this case I shall ever most\\r\\ncommonsely older to change me among them.\\r\\n\\r\\n\\xe2\\x80\\x9cHe\\xe2\\x80\\x99s appears that he was all in avoid senseless, I met\\r\\nher!\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cAnd it is neare you. There is a fierce eddy with Mr. and Mrs. Turner\\xe2\\x80\\x99s\\r\\njustice.\\xe2\\x80\\x99\\r\\n\\r\\n\\xe2\\x80\\x9c\\xe2\\x80\\x98No sign to matches the terest of, out that it was now to be found, from what it walked. It made\\r\\nher entirely listened in a very letter. As you are sould respance of it.\\r\\nOVER\\xe2\\x80\\x99 Not the man\\xe2\\x80\\x99s energe in lodgings in Barket-Street, a let treamed out her seemed to have\\r\\nhad ever ready upon the revulsion of amusem, and she rose knowledge of my own\\r\\neffect.\\r\\n\\r\\n127thing had saved his pocket by Mr. Aloysigh in its crop.\\xe2\\x80\\x9d\\r\\n\\r\\nI had some subtle held out of the two glasses of down with great redistence from she\\r\\nsprang'\n",
      " b'ROMEO:\\r\\n\\r\\n\\xe2\\x80\\x9cWhat are? But would have had her drop his brow of loafing cincess to a gale\\r\\nacross the floor. Then suddenly repairs a lay hastened out homes by frigntened expressions regarding up what was\\r\\nobvious upon the white carefulle street. A heads my ear needed in, but I\\r\\nfeared lokely through the street. The incident ghese consisted of amissies when we\\r\\nwanted very fill which draped up at him in report, you drove question in my\\r\\nBary, has a won thinks of home, I stepped from\\r\\nher attentions to London his eyes assistant. I can\\xe2\\x80\\x99temers to\\r\\nbe gown but that it would be sisper. Now I was all rud help, with the\\r\\ncharacter of money that there was a great coliable to\\r\\noffiction was on his Hampshire Ine. I have award by which she\\r\\nhas not sure with me who had an inexproce\\xe2\\x80\\x94that is why I have had made no\\r\\n   eeg and rately Holder, for he passed\\xe2\\x80\\x94among his own absence every\\r\\ndoably revolved as buttoned out on the tag with her assured abstation, and you can\\r\\ndark at my clothes.\\r\\n\\r\\n\\xe2\\x80\\x9cSo eate.\\xe2\\x80\\x9d\\r\\n\\r\\n\\xe2\\x80\\x9cYes, '], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.153136968612671\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x0000022B640539A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    }
   ],
   "source": [
    "#Exporting the generator\n",
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "\n",
      "Lord St. Simon breakfast and fuller rushed backward, and to the Alphar\n",
      "Wansons I. I have heard \n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized Training \n",
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 185s 2s/step - loss: 3.0482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b7622f610>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.3653\n",
      "Epoch 1 Batch 50 Loss 1.3561\n",
      "\n",
      "Epoch 1 Loss: 1.3647\n",
      "Time taken for 1 epoch 178.09 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 2 Batch 0 Loss 1.2861\n",
      "Epoch 2 Batch 50 Loss 1.3028\n",
      "\n",
      "Epoch 2 Loss: 1.2981\n",
      "Time taken for 1 epoch 178.30 sec\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Custom Training Loop\n",
    "EPOCHS = 2\n",
    "\n",
    "mean = tf.metrics.Mean()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    mean.reset_states()\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = model.train_step([inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "\n",
    "        if batch_n % 50 == 0:\n",
    "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
    "            print(template)\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print()\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
    "    print(\"_\"*80)\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdaf7c24b70b2679fb7e09fba8a86f4007a1bca4ea1511c38d4c08d31c6995f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
